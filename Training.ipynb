{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18e021f",
   "metadata": {},
   "source": [
    "# Anomaly Detection Training\n",
    "\n",
    "This notebook implements the training and evaluation of the anomaly detection model using the CustomVGG architecture, matching the latest codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b52293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import gc\n",
    "\n",
    "from utils.dataloader import get_train_loaders, get_test_loaders\n",
    "from utils.model import CustomVGG\n",
    "from utils.helper import train, evaluate, plot_dataset_comparison\n",
    "from utils.constants import NEG_CLASS, INPUT_IMG_SIZE\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc482a0",
   "metadata": {},
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272d326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0005\n",
    "NUM_EPOCHS = 20\n",
    "CLASS_WEIGHTS = torch.tensor([1.0, 3.0])\n",
    "CLASSIFICATION_THRESHOLD = 16.00\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db808562",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956865fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = get_train_loaders(BATCH_SIZE)\n",
    "test_loader = get_test_loaders(BATCH_SIZE)\n",
    "print(f'Train batches: {len(train_loader)}, Validation batches: {len(val_loader)}, Test batches: {len(test_loader)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c4a13c",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b344253",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = nn.ReLU\n",
    "num_neurons = 64\n",
    "model = CustomVGG(activation=activation, num_neurons=num_neurons).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS.to(device), label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3407a55",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = train(\n",
    "    train_loader, val_loader, model, optimizer, criterion,\n",
    "    NUM_EPOCHS, device, target_train_accuracy=0.90, scheduler=scheduler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d951f99d",
   "metadata": {},
   "source": [
    "## Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf18448",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')\n",
    "plt.title('Accuracy Curves')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ecbbc",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c2d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, loss, conf_matrix = evaluate(model, test_loader, device)\n",
    "print(f'Accuracy: {accuracy:.4f}, Loss: {loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298725fc",
   "metadata": {},
   "source": [
    "## Additional Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]\n",
    "        preds = (outputs[:, 1] > CLASSIFICATION_THRESHOLD).long()\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(f'Balanced Accuracy: {balanced_acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9554c2",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('weights', exist_ok=True)\n",
    "torch.save(model.state_dict(), 'weights/trained_model.pt')\n",
    "print('Model saved to weights/trained_model.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a9fc7",
   "metadata": {},
   "source": [
    "## Results & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c37d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('results/metrics/experiment_results.csv')\n",
    "print('Columns in results:', results_df.columns.tolist())\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def safe_boxplot(x, y, title, filename):\n",
    "    if x in results_df.columns and y in results_df.columns:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.boxplot(x=x, y=y, data=results_df)\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join('results/plots/parameter_analysis/', filename))\n",
    "        plt.close()\n",
    "        print(f\"Saved: {filename}\")\n",
    "\n",
    "# Learning Rate Impact\n",
    "if 'learning_rate' in results_df.columns and 'accuracy' in results_df.columns and 'optimizer' in results_df.columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.lineplot(x='learning_rate', y='accuracy', hue='optimizer', data=results_df, marker='o')\n",
    "    plt.title('Accuracy vs Learning Rate')\n",
    "    plt.xscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/plots/parameter_analysis/learning_rate_impact.png')\n",
    "    plt.close()\n",
    "    print(\"Saved: learning_rate_impact.png\")\n",
    "\n",
    "safe_boxplot('optimizer', 'accuracy', 'Accuracy by Optimizer', 'optimizer_comparison.png')\n",
    "safe_boxplot('activation', 'accuracy', 'Accuracy by Activation Function', 'activation_impact.png')\n",
    "safe_boxplot('num_neurons', 'accuracy', 'Accuracy by Number of Neurons', 'neurons_impact.png')\n",
    "safe_boxplot('batch_size', 'accuracy', 'Accuracy by Batch Size', 'batch_size_impact.png')\n",
    "\n",
    "if 'balanced_accuracy' in results_df.columns:\n",
    "    safe_boxplot('optimizer', 'balanced_accuracy', 'Balanced Accuracy by Optimizer', 'optimizer_balanced_accuracy.png')\n",
    "    safe_boxplot('activation', 'balanced_accuracy', 'Balanced Accuracy by Activation Function', 'activation_balanced_accuracy.png')\n",
    "    safe_boxplot('num_neurons', 'balanced_accuracy', 'Balanced Accuracy by Number of Neurons', 'neurons_balanced_accuracy.png')\n",
    "    safe_boxplot('batch_size', 'balanced_accuracy', 'Balanced Accuracy by Batch Size', 'batch_size_balanced_accuracy.png')\n",
    "\n",
    "print(\"Parameter analysis plots generated.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
